
# 1.在堆上分配内存

```cpp
__global__
void f(int* ptr) {
  *ptr = 42;
}
int main() {
  int *ptr;
  checkCudaErrors(cudaMalloc(&ptr, sizeof(int)));
  f<<<1, 1>>>(ptr);
  checkCudaErrors(cudaDeviceSynchronize());
  cudaFree(ptr);
}
```

这时，假如说我们在`checkCudaErrors(cudaDeviceSynchronize());`后试图使用`printf("%d\n", *ptr);`来打印`ptr`存储的值会出现segment fault，原因是我们是在GPU上分配的内存，而直接使用printf用的是cpu上的内存值，

因此可以用 `cudaMemcpy`，他能够在 GPU 和 CPU 内存之间拷贝数据。

这里我们希望把 GPU 上的内存数据拷贝到 CPU 内存上，也就是从设备内存(device)到主机内存(host)，因此第四个参数指定为 `cudaMemcpyDeviceToHost`。

```cpp
__global__
void f(int* ptr) {
  *ptr = 42;
}
int main() {
  int *ptr;
  checkCudaErrors(cudaMalloc(&ptr, sizeof(int)));
  f<<<1, 1>>>(ptr);
  checkCudaErrors(cudaDeviceSynchronize());

  int res;
  checkCudaErrors(cudaMemcpy(&res, ptr, sizeof(int), cudaMemcpyDeviceToHost));
  printf("res: %d\n", res);
  cudaFree(ptr);
}
```

同理，还有 `cudaMemcpyHostToDevice` 和 `cudaMemcpyDeviceToDevice`。

注意：`cudaMemcpy` 会自动进行同步操作，即和 `cudaDeviceSynchronize()` 等价！因此前面的 `cudaDeviceSynchronize()` 实际上可以删掉了：

```cpp
__global__
void f(int* ptr) {
  *ptr = 42;
}
int main() {
  int *ptr;
  checkCudaErrors(cudaMalloc(&ptr, sizeof(int)));
  f<<<1, 1>>>(ptr);

  int res;
  checkCudaErrors(cudaMemcpy(&res, ptr, sizeof(int), cudaMemcpyDeviceToHost));
  printf("res: %d\n", res);
  cudaFree(ptr);
}
```

还有一种在比较新的显卡上支持的特性，那就是统一内存(managed)，只需把 `cudaMalloc` 换成 `cudaMallocManaged` 即可，释放时也是通过 `cudaFree`。这样分配出来的地址，不论在 CPU 还是 GPU 上都是一模一样的，都可以访问。而且拷贝也会自动按需进行（当从 CPU 访问时），无需手动调用 `cudaMemcpy`，大大方便了编程人员，特别是含有指针的一些数据结构：

```cpp
int main() {
  int *ptr;
  checkCudaErrors(cudaMallocManaged(&ptr, sizeof(int)));
  f<<<1, 1>>>(ptr);
  checkCudaErrors(cudaDeviceSynchronize());
  printf("res: %d\n", *ptr);
  cudaFree(ptr);
}
```

## 分配数组

如 malloc 一样，可以用 `cudaMalloc` 配合 `n * sizeof(int)`，分配一个大小为 n 的整型数组。这样就会有 n 个连续的 int 数据排列在内存中，而 arr 则是指向其起始地址。然后把 arr 指针传入 f，即可在里面用 `arr[i]` 访问他的第 i 个元素：

```cpp
__global__
void f(int* arr, int n) {
  for (int i = 0; i < n; i++) {
    arr[i] = i;
  }
}
int main() {
  int *arr;
  int n = 32;
  checkCudaErrors(cudaMallocManaged(&arr, n * sizeof(int)));
  f<<<1, 1>>>(arr, n);
  checkCudaErrors(cudaDeviceSynchronize());
  for (int i = 0; i < n; i++) {
    printf("%d ", arr[i]);
  }
  printf("\n");
  cudaFree(arr);
}
```

刚刚的 for 循环是串行的，我们可以把线程数量调为 n，然后用 `threadIdx.x` 作为 i 索引。这样就实现了，每个线程负责给数组中一个元素的赋值。

```cpp
__global__
void f(int* arr, int n) {
  int i = threadIdx.x;
  arr[i] = i;
}
int main() {
  int *arr;
  int n = 32;
  checkCudaErrors(cudaMallocManaged(&arr, n * sizeof(int)));
  f<<<1, n>>>(arr, n);
  checkCudaErrors(cudaDeviceSynchronize());
  for (int i = 0; i < n; i++) {
    printf("%d ", arr[i]);
  }
  printf("\n");
  cudaFree(arr);
}
```

网格跨步循环：

无论调用者指定了多少个线程（blockDim），都能自动根据给定的 n 区间循环，不会越界，也不会漏掉几个元素。这样一个 for 循环非常符合 CPU 上常见的 parallel for 的习惯，又能自动匹配不同的 blockDim，看起来非常方便：

```cpp
__global__
void f(int* arr, int n) {
  for (int i = threadIdx.x; i < n; i += blockDim.x) {
    arr[i] = i;
  }
}
int main() {
  int *arr;
  int n = 7;
  checkCudaErrors(cudaMallocManaged(&arr, n * sizeof(int)));
  f<<<1, 4>>>(arr, n);
  checkCudaErrors(cudaDeviceSynchronize());
  for (int i = 0; i < n; i++) {
    printf("%d ", arr[i]);
  }
  printf("\n");
  cudaFree(arr);
}
```

核函数内部，用之前说到的 `blockDim.x + blockIdx.x + threadIdx.x` 来获取线程在整个网格中编号。外部调用者，则是根据不同的 n 决定板块的数量（`gridDim`），而每个板块具有的线程数量（`blockDim`）则是固定的 128。因此，我们可以用 `n / 128` 作为 `gridDim`，这样总的线程数刚好的 n，实现了每个线程负责处理一个元素。

```cpp
__global__
void f(int* arr, int n) {
  int i = blockDim.x * blockIdx.x + threadIdx.x;
  arr[i] = i;
}
int main() {
  int *arr;
  int n = 65536;
  checkCudaErrors(cudaMallocManaged(&arr, n * sizeof(int)));
  int nthreads = 128;
  int nblocks = n / nthreads;
  f<<<nblocks, nthreads>>>(arr, n);
  checkCudaErrors(cudaDeviceSynchronize());
  for (int i = 0; i < n; i++) {
    printf("%d ", arr[i]);
  }
  printf("\n");
  cudaFree(arr);
}
```

但这样要求n必须为128的倍数，否则最后几个元素会出现没有赋值的情况，因此我们采用向上取整的除法：

```cpp
int nblocks = (n + nthreads - 1) / nthreads;
```

网格跨步循环：应用于线程和板块一起上的情况：

```cpp
__global__
void f(int* arr, int n) {
  for (int i = blockDim.x * blockIdx.x + threadIdx.x; i < n; i += blockDim.x * gridDim.x) {
    arr[i] = i;
  }
}
int main() {
  int *arr;
  int n = 65536;
  checkCudaErrors(cudaMallocManaged(&arr, n * sizeof(int)));
  f<<<32, 128>>>(arr, n);
  checkCudaErrors(cudaDeviceSynchronize());
  for (int i = 0; i < n; i++) {
    printf("%d ", arr[i]);
  }
  printf("\n");
  cudaFree(arr);
}
```

# thrust 库的使用

`universal_vector` 会在统一内存上分配，因此不论 GPU 还是 CPU 都可以直接访问到

```cpp
#include <cstdio>
#include <cstdlib>
#include <cuda_runtime.h>
#include <thrust/universal_vector.h>
#include "helper_cuda.h"

template <class Func>
__global__
void parallel_for(int n, Func func) {
  for (int i = blockDim.x * blockIdx.x + threadIdx.x; i < n; i += blockDim.x * gridDim.x) {
    func(i);
  }
}
int main() {
  int n = 65536;
  float a = 3.14f;
  thrust::universal_vector<float> x(n);
  thrust::universal_vector<float> y(n);
  for (int i = 0; i < n; i++) {
    x[i] = std::rand() * 1.f / RAND_MAX;
    y[i] = std::rand() * 1.f / RAND_MAX;
  }
  parallel_for<<<n / 128, 128>>>(n, [a, x = x.data(), y = y.data()] __device__ (int i) {
    x[i] = a * x[i] + y[i];
  });
  checkCudaErrors(cudaDeviceSynchronize());  // 使用universal_vector必须同步
  for (int i = 0; i < n; i++) {
    printf("x[%d] = %f\n", i, x[i]);
  }
}
```

而 `device_vector` 则是在 GPU 上分配内存，`host_vector` 在 CPU 上分配内存。
可以通过 = 运算符在 `device_vector` 和 `host_vector` 之间拷贝数据，他会自动帮你调用 `cudaMemcpy`，非常智能。

```cpp
#include <cstdio>
#include <cstdlib>
#include <cuda_runtime.h>
#include <thrust/device_vector.h>
#include <thrust/host_vector.h>
#include "helper_cuda.h"


template <class Func>
__global__
void parallel_for(int n, Func func) {
  for (int i = blockDim.x * blockIdx.x + threadIdx.x; i < n; i += blockDim.x * gridDim.x) {
    func(i);
  }
}
int main() {
  int n = 65536;
  float a = 3.14f;
  thrust::host_vector<float> x_host(n);
  thrust::host_vector<float> y_host(n);
  for (int i = 0; i < n; i++) {
    x_host[i] = std::rand() * 1.f / RAND_MAX;
    y_host[i] = std::rand() * 1.f / RAND_MAX;
  }
  thrust::device_vector<float> x_dev = x_host;
  thrust::device_vector<float> y_dev = y_host;


  parallel_for<<<n / 128, 128>>>(n, [a, x_dev = x_dev.data(), y_dev = y_dev.data()] __device__ (int i) {
    x_dev[i] = a * x_dev[i] + y_dev[i];
  });
  x_host = x_dev;
  for (int i = 0; i < n; i++) {
    printf("x[%d] = %f\n", i, x_host[i]);
  }
}
```

使用`thrust::generate`优化写法：

```cpp
#include <cstdio>
#include <cstdlib>
#include <cuda_runtime.h>
#include <thrust/device_vector.h>
#include <thrust/host_vector.h>
#include <thrust/generate.h>

#include "helper_cuda.h"

template <class Func>
__global__
void parallel_for(int n, Func func) {
  for (int i = blockDim.x * blockIdx.x + threadIdx.x; i < n; i += blockDim.x * gridDim.x) {
    func(i);
  }
}
int main() {
  int n = 65536;
  float a = 3.14f;
  thrust::host_vector<float> x_host(n);
  thrust::host_vector<float> y_host(n);
  auto floatRand = []() {
    return std::rand() * 1.f / RAND_MAX;
  };
  thrust::generate(x_host.begin(), x_host.end(), floatRand);
  thrust::generate(y_host.begin(), y_host.end(), floatRand);

  thrust::device_vector<float> x_dev = x_host;
  thrust::device_vector<float> y_dev = y_host;


  parallel_for<<<n / 128, 128>>>(n, [a, x_dev = x_dev.data(), y_dev = y_dev.data()] __device__ (int i) {
    x_dev[i] = a * x_dev[i] + y_dev[i];
  });
  x_host = x_dev;
  for (int i = 0; i < n; i++) {
    printf("x[%d] = %f\n", i, x_host[i]);
  }
}
```

同理，还有 thrust::for_each(b, e, f) 对标 std::for_each。他会把 `[b, e)` 区间的每个元素 x 调用一遍 f(x)。这里的 x 实际上是一个引用。如果 b 和 e 是常值迭代器则是个常引用，可以用 cbegin()，cend() 获取常值迭代器。
当然还有 `thrust::reduce`，`thrust::sort`，`thrust::find_if`，`thrust::count_if`，`thrust::reverse`，`thrust::inclusive_scan` 等。

# 原子操作

由于 gpu 上的操作是并行执行的，因此在很多情况下我们需要提供锁来保证正常执行

考虑数组相加的例子：

```cpp
#include <cstdio>
#include <cuda_runtime.h>

#include "helper_cuda.h"

__global__
void parallel_sum(int* sum, const int* arr, int n) {
  for (int i = blockDim.x * blockIdx.x + threadIdx.x; i < n; i += blockDim.x * gridDim.x) {
    atomicAdd(sum, arr[i]);
  }
}
int main() {
  int n = 100;
  int* arr;
  checkCudaErrors(cudaMallocManaged(&arr, sizeof(int) * n));
  int ans = 0;
  for (int i = 0; i < n; i++) {
    arr[i] = std::rand() % 10;
    ans += arr[i];
  }
  printf("%d\n", ans);
  int* sum;
  checkCudaErrors(cudaMallocManaged(&sum, sizeof(int)));
  *sum = 0;
  parallel_sum<<<1, 100>>>(sum, arr, n);
  checkCudaErrors(cudaDeviceSynchronize());
  printf("%d\n", *sum);
  cudaFree(sum);
  cudaFree(arr);
}
```


